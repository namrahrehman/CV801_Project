{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU Setup and Detection Notebook\n",
    "\n",
    "This notebook detects and configures available GPUs for use with PyTorch and other deep learning frameworks.\n",
    "\n",
    "## Available GPUs\n",
    "The system has 8 NVIDIA A100 GPUs (40GB each) available.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Set CUDA_VISIBLE_DEVICES=1,3,5\n",
      "✓ Free GPUs detected: [1, 3, 5] (3 GPUs)\n",
      "\n",
      "PyTorch version: 2.5.1+cu121\n",
      "CUDA available: True\n",
      "CUDA version: 12.1\n",
      "cuDNN version: 90100\n",
      "✓ Visible GPUs: 3\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CRITICAL: Run this cell FIRST. If you see an error, restart kernel first!\n",
    "# ============================================================================\n",
    "import sys\n",
    "\n",
    "# Safety check: torch must NOT be imported yet\n",
    "if 'torch' in sys.modules:\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"⚠️  ERROR: torch is already imported!\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"\\nYou MUST:\")\n",
    "    print(\"  1. Restart the kernel (Kernel → Restart Kernel)\")\n",
    "    print(\"  2. Run this cell FIRST (before any other cells)\")\n",
    "    print(\"\\nCUDA_VISIBLE_DEVICES must be set BEFORE importing torch.\")\n",
    "    print(\"=\"*70)\n",
    "    raise RuntimeError(\"Please restart kernel and run this cell first!\")\n",
    "\n",
    "# STEP 1: Find free GPUs BEFORE importing torch\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "def find_free_gpus():\n",
    "    \"\"\"Find GPUs with low memory usage and available\"\"\"\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            ['nvidia-smi', '--query-gpu=index,memory.used,memory.total,utilization.gpu', '--format=csv,noheader,nounits'],\n",
    "            capture_output=True, text=True, check=True, timeout=5\n",
    "        )\n",
    "        free_gpus = []\n",
    "        for line in result.stdout.strip().split('\\n'):\n",
    "            if line.strip():\n",
    "                parts = [p.strip() for p in line.split(',')]\n",
    "                gpu_id = int(parts[0])\n",
    "                used = int(parts[1])\n",
    "                total = int(parts[2])\n",
    "                util = parts[3] if len(parts) > 3 else '0'\n",
    "                \n",
    "                usage_pct = (used / total) * 100\n",
    "                free_mb = total - used\n",
    "                \n",
    "                # More conservative: require < 5% usage AND > 35GB free AND not busy\n",
    "                if usage_pct < 5 and free_mb > 35000 and util != '[N/A]':\n",
    "                    try:\n",
    "                        util_val = int(util) if util != '[N/A]' else 100\n",
    "                        if util_val < 10:  # Less than 10% utilization\n",
    "                            free_gpus.append(gpu_id)\n",
    "                    except:\n",
    "                        pass\n",
    "        \n",
    "        # If no GPUs found with strict criteria, be more lenient\n",
    "        if not free_gpus:\n",
    "            print(\"⚠️  No GPUs found with strict criteria, using lenient check...\")\n",
    "            for line in result.stdout.strip().split('\\n'):\n",
    "                if line.strip():\n",
    "                    parts = [p.strip() for p in line.split(',')]\n",
    "                    gpu_id = int(parts[0])\n",
    "                    used = int(parts[1])\n",
    "                    total = int(parts[2])\n",
    "                    usage_pct = (used / total) * 100\n",
    "                    free_mb = total - used\n",
    "                    if usage_pct < 10 and free_mb > 30000:\n",
    "                        free_gpus.append(gpu_id)\n",
    "        \n",
    "        return free_gpus if free_gpus else [5]  # Default to GPU 5 if none found\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not check GPU status: {e}\")\n",
    "        return [5]  # Default safe GPU\n",
    "\n",
    "free_gpus = find_free_gpus()\n",
    "\n",
    "# STEP 2: Set CUDA_VISIBLE_DEVICES BEFORE importing torch\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ','.join(map(str, free_gpus))\n",
    "print(f\"\\n✓ Set CUDA_VISIBLE_DEVICES={os.environ['CUDA_VISIBLE_DEVICES']}\")\n",
    "print(f\"✓ Free GPUs detected: {free_gpus} ({len(free_gpus)} GPU{'s' if len(free_gpus) != 1 else ''})\")\n",
    "\n",
    "# STEP 3: NOW import torch (it will only see the free GPUs)\n",
    "import torch\n",
    "\n",
    "print(f\"\\nPyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"cuDNN version: {torch.backends.cudnn.version()}\")\n",
    "    num_visible = torch.cuda.device_count()\n",
    "    print(f\"✓ Visible GPUs: {num_visible}\")\n",
    "    if num_visible != len(free_gpus):\n",
    "        print(\"\\n⚠️  WARNING: GPU count mismatch! Restart kernel and run this cell again.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "GPU Information (Only Free GPUs are Visible)\n",
      "============================================================\n",
      "\n",
      "✓ Number of visible GPUs: 3\n",
      "✓ CUDA_VISIBLE_DEVICES: 1,3,5\n",
      "\n",
      "All GPU Status (from nvidia-smi):\n",
      "0, NVIDIA A100-PCIE-40GB, 18679, 40960, 0\n",
      "1, NVIDIA A100-PCIE-40GB, 463, 40960, 0\n",
      "2, NVIDIA A100-PCIE-40GB, 4, 40960, [N/A]\n",
      "3, NVIDIA A100-PCIE-40GB, 431, 40960, 0\n",
      "4, NVIDIA A100-PCIE-40GB, 9496, 40960, 33\n",
      "5, NVIDIA A100-PCIE-40GB, 4, 40960, 0\n",
      "6, NVIDIA A100-PCIE-40GB, 40401, 40960, 100\n",
      "7, NVIDIA A100-PCIE-40GB, 28733, 40960, 0\n",
      "\n",
      "\n",
      "PyTorch Visible GPUs:\n",
      "\n",
      "  GPU 0:\n",
      "    Name: NVIDIA A100-PCIE-40GB\n",
      "    Memory: 39.49 GB\n",
      "    Compute Capability: 8.0\n",
      "\n",
      "  GPU 1:\n",
      "    Name: NVIDIA A100-PCIE-40GB\n",
      "    Memory: 39.49 GB\n",
      "    Compute Capability: 8.0\n",
      "\n",
      "  GPU 2:\n",
      "    Name: NVIDIA A100-PCIE-40GB\n",
      "    Memory: 39.49 GB\n",
      "    Compute Capability: 8.0\n",
      "\n",
      "✓ Default device set to: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Display detailed GPU information\n",
    "\n",
    "# Check if CUDA_VISIBLE_DEVICES was set (should be set in Cell 1)\n",
    "cuda_visible = os.environ.get('CUDA_VISIBLE_DEVICES', '')\n",
    "if not cuda_visible:\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"⚠️  WARNING: CUDA_VISIBLE_DEVICES is not set!\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"\\nYou MUST:\")\n",
    "    print(\"  1. Restart the kernel (Kernel → Restart Kernel)\")\n",
    "    print(\"  2. Run Cell 1 FIRST (it sets CUDA_VISIBLE_DEVICES)\")\n",
    "    print(\"  3. Then run this cell\")\n",
    "    print(\"Without CUDA_VISIBLE_DEVICES, PyTorch will see all 8 GPUs\")\n",
    "    print(\"and may encounter initialization errors.\")\n",
    "    print(\"=\"*70)\n",
    "    raise RuntimeError(\"Please run Cell 1 first after restarting kernel!\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"GPU Information (Only Free GPUs are Visible)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    print(f\"\\n✓ Number of visible GPUs: {num_gpus}\")\n",
    "    print(f\"✓ CUDA_VISIBLE_DEVICES: {cuda_visible}\")\n",
    "    \n",
    "    # Verify GPU count matches expected\n",
    "    expected_gpus = len(cuda_visible.split(','))\n",
    "    if num_gpus != expected_gpus:\n",
    "        print(f\"\\n⚠️  WARNING: Expected {expected_gpus} GPUs but PyTorch sees {num_gpus}\")\n",
    "        print(\"   This might mean Cell 1 didn't run properly. Restart kernel and run Cell 1 first.\")\n",
    "    \n",
    "    # Show all GPU status from nvidia-smi\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            ['nvidia-smi', '--query-gpu=index,name,memory.used,memory.total,utilization.gpu', '--format=csv,noheader,nounits'],\n",
    "            capture_output=True, text=True, check=True, timeout=5\n",
    "        )\n",
    "        print(\"\\nAll GPU Status (from nvidia-smi):\")\n",
    "        print(result.stdout)\n",
    "    except Exception as e:\n",
    "        print(f\"Could not get GPU status: {e}\")\n",
    "    \n",
    "    # Show PyTorch visible GPUs (with error handling)\n",
    "    print(\"\\nPyTorch Visible GPUs:\")\n",
    "    for i in range(num_gpus):\n",
    "        try:\n",
    "            print(f\"\\n  GPU {i}:\")\n",
    "            print(f\"    Name: {torch.cuda.get_device_name(i)}\")\n",
    "            props = torch.cuda.get_device_properties(i)\n",
    "            print(f\"    Memory: {props.total_memory / 1024**3:.2f} GB\")\n",
    "            print(f\"    Compute Capability: {props.major}.{props.minor}\")\n",
    "        except Exception as e:\n",
    "            print(f\"    ⚠️  Error accessing GPU {i}: {str(e)[:100]}...\")\n",
    "            print(f\"    This GPU may be busy or have initialization issues.\")\n",
    "    \n",
    "    # Set default device\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    print(f\"\\n✓ Default device set to: {device}\")\n",
    "else:\n",
    "    print(\"CUDA is not available.\")\n",
    "    device = torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using existing device: cuda:0\n",
      "✓ GPU cache cleared\n",
      "\n",
      "✓ Available GPUs: 3\n",
      "\n",
      "GPU Memory Status:\n",
      "  GPU 0: 42.4 GB free (total: 42.4 GB, reserved: 0.00 GB)\n",
      "  GPU 1: 42.4 GB free (total: 42.4 GB, reserved: 0.00 GB)\n",
      "  GPU 2: 42.4 GB free (total: 42.4 GB, reserved: 0.00 GB)\n",
      "\n",
      "✓ Using single GPU mode for reliability\n",
      "✓ Model moved to device: cuda:0\n",
      "\n",
      "✓ Forward pass successful!\n",
      "  Input shape: torch.Size([8, 100])\n",
      "  Output shape: torch.Size([8, 100])\n",
      "  Output device: cuda:0\n",
      "✓ Test tensors cleaned up\n",
      "\n",
      "--- Optional: Testing DataParallel ---\n",
      "✓ DataParallel test successful! Output: torch.Size([4, 100])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/namrah/miniconda3/envs/project/lib/python3.10/site-packages/torch/nn/modules/linear.py:125: UserWarning: Attempting to run cuBLAS, but there was no current CUDA context! Attempting to set the primary context... (Triggered internally at ../aten/src/ATen/cuda/CublasHandlePool.cpp:135.)\n",
      "  return F.linear(input, self.weight, self.bias)\n"
     ]
    }
   ],
   "source": [
    "# Set default device (if not already set)\n",
    "if 'device' not in globals():\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda:0\")\n",
    "        print(f\"✓ Set device: {device}\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(\"CUDA not available, using CPU\")\n",
    "else:\n",
    "    print(f\"Using existing device: {device}\")\n",
    "\n",
    "# Clear GPU cache before testing\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"✓ GPU cache cleared\")\n",
    "\n",
    "# Example: GPU testing (using single GPU for reliability)\n",
    "if torch.cuda.is_available():\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    print(f\"\\n✓ Available GPUs: {num_gpus}\")\n",
    "    \n",
    "    # Check memory on each GPU\n",
    "    print(\"\\nGPU Memory Status:\")\n",
    "    for i in range(num_gpus):\n",
    "        try:\n",
    "            props = torch.cuda.get_device_properties(i)\n",
    "            allocated = torch.cuda.memory_allocated(i) / 1e9\n",
    "            reserved = torch.cuda.memory_reserved(i) / 1e9\n",
    "            total = props.total_memory / 1e9\n",
    "            free = total - reserved\n",
    "            print(f\"  GPU {i}: {free:.1f} GB free (total: {total:.1f} GB, reserved: {reserved:.2f} GB)\")\n",
    "        except Exception as e:\n",
    "            print(f\"  GPU {i}: Error checking memory - {e}\")\n",
    "    \n",
    "    # Example model (small for testing)\n",
    "    class SimpleModel(torch.nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.linear = torch.nn.Linear(100, 100)  # Small model\n",
    "        \n",
    "        def forward(self, x):\n",
    "            return self.linear(x)\n",
    "    \n",
    "    # Use single GPU mode (more reliable than DataParallel)\n",
    "    print(\"\\n✓ Using single GPU mode for reliability\")\n",
    "    model = SimpleModel().to(device)\n",
    "    print(f\"✓ Model moved to device: {next(model.parameters()).device}\")\n",
    "    \n",
    "    # Test forward pass\n",
    "    try:\n",
    "        test_input = torch.randn(8, 100, device=device)\n",
    "        output = model(test_input)\n",
    "        print(f\"\\n✓ Forward pass successful!\")\n",
    "        print(f\"  Input shape: {test_input.shape}\")\n",
    "        print(f\"  Output shape: {output.shape}\")\n",
    "        print(f\"  Output device: {output.device}\")\n",
    "        \n",
    "        # Clean up\n",
    "        del test_input, output\n",
    "        torch.cuda.empty_cache()\n",
    "        print(\"✓ Test tensors cleaned up\")\n",
    "        \n",
    "        # Optional: Test DataParallel if user wants\n",
    "        print(\"\\n--- Optional: Testing DataParallel ---\")\n",
    "        if num_gpus > 1:\n",
    "            try:\n",
    "                torch.cuda.empty_cache()\n",
    "                parallel_model = torch.nn.DataParallel(SimpleModel()).to(device)\n",
    "                test_input = torch.randn(4, 100, device=device)  # Smaller batch for DataParallel\n",
    "                output = parallel_model(test_input)\n",
    "                print(f\"✓ DataParallel test successful! Output: {output.shape}\")\n",
    "                del parallel_model, test_input, output\n",
    "                torch.cuda.empty_cache()\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️  DataParallel test failed: {e}\")\n",
    "                print(\"  Single GPU mode works fine - use that for your work.\")\n",
    "        else:\n",
    "            print(\"  Only 1 GPU available, skipping DataParallel test\")\n",
    "            \n",
    "    except RuntimeError as e:\n",
    "        if \"out of memory\" in str(e).lower():\n",
    "            print(f\"\\n✗ Out of memory error: {e}\")\n",
    "            print(\"\\n  Troubleshooting:\")\n",
    "            print(\"    1. Check GPU status: nvidia-smi\")\n",
    "            print(\"    2. Some GPUs may appear free but have reserved memory\")\n",
    "            print(\"    3. Try using a different GPU or reduce batch size\")\n",
    "        else:\n",
    "            print(f\"\\n✗ Forward pass failed: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n✗ Unexpected error: {e}\")\n",
    "else:\n",
    "    print(\"CUDA not available - cannot test GPU functionality\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Setup for multi-GPU training\n",
    "def setup_multi_gpu(model, device_ids=None):\n",
    "    \"\"\"\n",
    "    Setup model for multi-GPU training\n",
    "    \n",
    "    Args:\n",
    "        model: PyTorch model\n",
    "        device_ids: List of GPU IDs to use (default: all available)\n",
    "    \n",
    "    Returns:\n",
    "        Model wrapped in DataParallel\n",
    "    \"\"\"\n",
    "    if not torch.cuda.is_available():\n",
    "        return model.to(torch.device(\"cpu\"))\n",
    "    \n",
    "    if device_ids is None:\n",
    "        device_ids = list(range(torch.cuda.device_count()))\n",
    "    \n",
    "    if len(device_ids) > 1:\n",
    "        model = torch.nn.DataParallel(model, device_ids=device_ids)\n",
    "        print(f\"Model wrapped in DataParallel for GPUs: {device_ids}\")\n",
    "    else:\n",
    "        model = model.to(torch.device(f\"cuda:{device_ids[0]}\"))\n",
    "        print(f\"Model moved to GPU {device_ids[0]}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Example usage:\n",
    "# model = YourModel()\n",
    "# model = setup_multi_gpu(model)  # Use all GPUs\n",
    "# model = setup_multi_gpu(model, device_ids=[0, 1, 2, 3])  # Use specific GPUs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Variables\n",
    "\n",
    "You can control GPU visibility using environment variables:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install \"transformers>=4.44\" accelerate torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu121\n",
    "!pip -q install pillow opencv-python rapidfuzz tqdm matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Point to the folder that contains dataset_dict.json (NOT directly to train/)\n",
    "VQARAD_PATH = \"/home/namrah/project/data/VQA_RAD\"\n",
    "\n",
    "# Do the same for SLAKE when you place it (adjust this to your actual path):\n",
    "SLAKE_PATH  = \"/home/namrah/project/data/SLAKE\"\n",
    "\n",
    "OUT_DIR = \"/home/namrah/project/data/outputs_cfproxy\"\n",
    "!mkdir -p \"$OUT_DIR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['image', 'question', 'answer'],\n",
      "        num_rows: 1793\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['image', 'question', 'answer'],\n",
      "        num_rows: 451\n",
      "    })\n",
      "})\n",
      "dict_keys(['image', 'question', 'answer'])\n",
      "is there evidence of an aortic aneurysm? -> yes\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "vqa_rad = load_from_disk(VQARAD_PATH)  # returns a DatasetDict because dataset_dict.json exists\n",
    "print(vqa_rad)                         # Expect: DatasetDict with 'train' and 'test'\n",
    "\n",
    "# Pick a split\n",
    "vqa_rad_train = vqa_rad[\"train\"]\n",
    "vqa_rad_test  = vqa_rad[\"test\"]\n",
    "\n",
    "# Quick sanity check\n",
    "row = vqa_rad_test[0]\n",
    "print(row.keys())       # -> dict_keys(['image','question','answer', ...])\n",
    "print(row[\"question\"], \"->\", row[\"answer\"])\n",
    "row[\"image\"].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "Path(OUT_DIR).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "from datasets import load_from_disk\n",
    "vqa = load_from_disk(VQARAD_PATH)\n",
    "ds_train, ds_test = vqa[\"train\"], vqa[\"test\"]\n",
    "\n",
    "def iter_samples(ds, n=None):\n",
    "    m = len(ds) if n is None else min(n, len(ds))\n",
    "    for i in range(m):\n",
    "        r = ds[i]\n",
    "        yield i, r[\"image\"], r[\"question\"], r[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: Qwen/Qwen2-VL-2B-Instruct\n",
      "Device: cuda\n",
      "⚠️  Warning: Optional file missing (404 Client Error. (Request ID: Root=1-691b89b0-228160741791331e251b85bc;2ba16ceb-0e94-4d29-983b-6acced2d6a6f)\n",
      "\n",
      "Entry Not Found for url: https://huggingface.co/api/models/Qwen/Qwen2-VL-2B-Instruct/tree/main/additional_chat_templates?recursive=false&expand=false.\n",
      "additional_chat_templates does not exist on \"main\"), continuing anyway...\n",
      "✗ Could not load processor: 404 Client Error. (Request ID: Root=1-691b89b2-6e0156535b770da2200d5812;4e982243-0128-425c-8e7c-2b7d756cdc8e)\n",
      "\n",
      "Entry Not Found for url: https://huggingface.co/api/models/Qwen/Qwen2-VL-2B-Instruct/tree/main/additional_chat_templates?recursive=false&expand=false.\n",
      "additional_chat_templates does not exist on \"main\"\n"
     ]
    },
    {
     "ename": "RemoteEntryNotFoundError",
     "evalue": "404 Client Error. (Request ID: Root=1-691b89b2-6e0156535b770da2200d5812;4e982243-0128-425c-8e7c-2b7d756cdc8e)\n\nEntry Not Found for url: https://huggingface.co/api/models/Qwen/Qwen2-VL-2B-Instruct/tree/main/additional_chat_templates?recursive=false&expand=false.\nadditional_chat_templates does not exist on \"main\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPStatusError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/project/lib/python3.10/site-packages/huggingface_hub/utils/_http.py:553\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    552\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_curlify\u001b[39m(request: requests\u001b[38;5;241m.\u001b[39mPreparedRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m--> 553\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Convert a `requests.PreparedRequest` into a curl command (str).\u001b[39;00m\n\u001b[1;32m    554\u001b[0m \n\u001b[1;32m    555\u001b[0m \u001b[38;5;124;03m    Used for debug purposes only.\u001b[39;00m\n\u001b[1;32m    556\u001b[0m \n\u001b[1;32m    557\u001b[0m \u001b[38;5;124;03m    Implementation vendored from https://github.com/ofw/curlify/blob/master/curlify.py.\u001b[39;00m\n\u001b[1;32m    558\u001b[0m \u001b[38;5;124;03m    MIT License Copyright (c) 2016 Egor.\u001b[39;00m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    560\u001b[0m     parts: List[Tuple[Any, Any]] \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    561\u001b[0m         (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcurl\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    562\u001b[0m         (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-X\u001b[39m\u001b[38;5;124m\"\u001b[39m, request\u001b[38;5;241m.\u001b[39mmethod),\n\u001b[1;32m    563\u001b[0m     ]\n",
      "File \u001b[0;32m~/miniconda3/envs/project/lib/python3.10/site-packages/httpx/_models.py:829\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    828\u001b[0m message \u001b[38;5;241m=\u001b[39m message\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m, error_type\u001b[38;5;241m=\u001b[39merror_type)\n\u001b[0;32m--> 829\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m HTTPStatusError(message, request\u001b[38;5;241m=\u001b[39mrequest, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPStatusError\u001b[0m: Client error '404 Not Found' for url 'https://huggingface.co/api/models/Qwen/Qwen2-VL-2B-Instruct/tree/main/additional_chat_templates?recursive=false&expand=false'\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRemoteEntryNotFoundError\u001b[0m                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 14\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 14\u001b[0m     processor \u001b[38;5;241m=\u001b[39m \u001b[43mAutoProcessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[43mMODEL_ID\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✓ Processor loaded successfully\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/project/lib/python3.10/site-packages/transformers/models/auto/processing_auto.py:396\u001b[0m, in \u001b[0;36mAutoProcessor.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m processor_class \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 396\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprocessor_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;66;03m# Last try: we use the PROCESSOR_MAPPING.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/project/lib/python3.10/site-packages/transformers/processing_utils.py:1394\u001b[0m, in \u001b[0;36mProcessorMixin.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, **kwargs)\u001b[0m\n\u001b[1;32m   1392\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m token\n\u001b[0;32m-> 1394\u001b[0m args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_arguments_from_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1395\u001b[0m processor_dict, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mget_processor_dict(pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/project/lib/python3.10/site-packages/transformers/processing_utils.py:1453\u001b[0m, in \u001b[0;36mProcessorMixin._get_arguments_from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m   1451\u001b[0m         attribute_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mget_possibly_dynamic_module(class_name)\n\u001b[0;32m-> 1453\u001b[0m     args\u001b[38;5;241m.\u001b[39mappend(\u001b[43mattribute_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1455\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m args\n",
      "File \u001b[0;32m~/miniconda3/envs/project/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2038\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   2037\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2038\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m template \u001b[38;5;129;01min\u001b[39;00m \u001b[43mlist_repo_templates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2039\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2040\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2041\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2042\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2043\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2044\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   2045\u001b[0m         template \u001b[38;5;241m=\u001b[39m template\u001b[38;5;241m.\u001b[39mremovesuffix(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.jinja\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/project/lib/python3.10/site-packages/transformers/utils/hub.py:167\u001b[0m, in \u001b[0;36mlist_repo_templates\u001b[0;34m(repo_id, local_files_only, revision, cache_dir, token)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 167\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m    168\u001b[0m         entry\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mremoveprefix(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mCHAT_TEMPLATE_DIR\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    169\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m entry \u001b[38;5;129;01min\u001b[39;00m list_repo_tree(\n\u001b[1;32m    170\u001b[0m             repo_id\u001b[38;5;241m=\u001b[39mrepo_id,\n\u001b[1;32m    171\u001b[0m             revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[1;32m    172\u001b[0m             path_in_repo\u001b[38;5;241m=\u001b[39mCHAT_TEMPLATE_DIR,\n\u001b[1;32m    173\u001b[0m             recursive\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    174\u001b[0m             token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[1;32m    175\u001b[0m         )\n\u001b[1;32m    176\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m entry\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.jinja\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    177\u001b[0m     ]\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (GatedRepoError, RepositoryNotFoundError, RevisionNotFoundError):\n",
      "File \u001b[0;32m~/miniconda3/envs/project/lib/python3.10/site-packages/transformers/utils/hub.py:167\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 167\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m    168\u001b[0m         entry\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mremoveprefix(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mCHAT_TEMPLATE_DIR\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    169\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m entry \u001b[38;5;129;01min\u001b[39;00m list_repo_tree(\n\u001b[1;32m    170\u001b[0m             repo_id\u001b[38;5;241m=\u001b[39mrepo_id,\n\u001b[1;32m    171\u001b[0m             revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[1;32m    172\u001b[0m             path_in_repo\u001b[38;5;241m=\u001b[39mCHAT_TEMPLATE_DIR,\n\u001b[1;32m    173\u001b[0m             recursive\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    174\u001b[0m             token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[1;32m    175\u001b[0m         )\n\u001b[1;32m    176\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m entry\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.jinja\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    177\u001b[0m     ]\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (GatedRepoError, RepositoryNotFoundError, RevisionNotFoundError):\n",
      "File \u001b[0;32m~/miniconda3/envs/project/lib/python3.10/site-packages/huggingface_hub/hf_api.py:3082\u001b[0m, in \u001b[0;36mlist_repo_tree\u001b[0;34m(self, repo_id, path_in_repo, recursive, expand, revision, repo_type, token)\u001b[0m\n\u001b[1;32m   3062\u001b[0m \u001b[38;5;129m@validate_hf_hub_args\u001b[39m\n\u001b[1;32m   3063\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mlist_repo_tree\u001b[39m(\n\u001b[1;32m   3064\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3072\u001b[0m     token: Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   3073\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterable[Union[RepoFile, RepoFolder]]:\n\u001b[1;32m   3074\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3075\u001b[0m \u001b[38;5;124;03m    List a repo tree's files and folders and get information about them.\u001b[39;00m\n\u001b[1;32m   3076\u001b[0m \n\u001b[1;32m   3077\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   3078\u001b[0m \u001b[38;5;124;03m        repo_id (`str`):\u001b[39;00m\n\u001b[1;32m   3079\u001b[0m \u001b[38;5;124;03m            A namespace (user or an organization) and a repo name separated by a `/`.\u001b[39;00m\n\u001b[1;32m   3080\u001b[0m \u001b[38;5;124;03m        path_in_repo (`str`, *optional*):\u001b[39;00m\n\u001b[1;32m   3081\u001b[0m \u001b[38;5;124;03m            Relative path of the tree (folder) in the repo, for example:\u001b[39;00m\n\u001b[0;32m-> 3082\u001b[0m \u001b[38;5;124;03m            `\"checkpoints/1fec34a/results\"`. Will default to the root tree (folder) of the repository.\u001b[39;00m\n\u001b[1;32m   3083\u001b[0m \u001b[38;5;124;03m        recursive (`bool`, *optional*, defaults to `False`):\u001b[39;00m\n\u001b[1;32m   3084\u001b[0m \u001b[38;5;124;03m            Whether to list tree's files and folders recursively.\u001b[39;00m\n\u001b[1;32m   3085\u001b[0m \u001b[38;5;124;03m        expand (`bool`, *optional*, defaults to `False`):\u001b[39;00m\n\u001b[1;32m   3086\u001b[0m \u001b[38;5;124;03m            Whether to fetch more information about the tree's files and folders (e.g. last commit and files' security scan results). This\u001b[39;00m\n\u001b[1;32m   3087\u001b[0m \u001b[38;5;124;03m            operation is more expensive for the server so only 50 results are returned per page (instead of 1000).\u001b[39;00m\n\u001b[1;32m   3088\u001b[0m \u001b[38;5;124;03m            As pagination is implemented in `huggingface_hub`, this is transparent for you except for the time it\u001b[39;00m\n\u001b[1;32m   3089\u001b[0m \u001b[38;5;124;03m            takes to get the results.\u001b[39;00m\n\u001b[1;32m   3090\u001b[0m \u001b[38;5;124;03m        revision (`str`, *optional*):\u001b[39;00m\n\u001b[1;32m   3091\u001b[0m \u001b[38;5;124;03m            The revision of the repository from which to get the tree. Defaults to `\"main\"` branch.\u001b[39;00m\n\u001b[1;32m   3092\u001b[0m \u001b[38;5;124;03m        repo_type (`str`, *optional*):\u001b[39;00m\n\u001b[1;32m   3093\u001b[0m \u001b[38;5;124;03m            The type of the repository from which to get the tree (`\"model\"`, `\"dataset\"` or `\"space\"`.\u001b[39;00m\n\u001b[1;32m   3094\u001b[0m \u001b[38;5;124;03m            Defaults to `\"model\"`.\u001b[39;00m\n\u001b[1;32m   3095\u001b[0m \u001b[38;5;124;03m        token (`bool` or `str`, *optional*):\u001b[39;00m\n\u001b[1;32m   3096\u001b[0m \u001b[38;5;124;03m            A valid user access token (string). Defaults to the locally saved\u001b[39;00m\n\u001b[1;32m   3097\u001b[0m \u001b[38;5;124;03m            token, which is the recommended method for authentication (see\u001b[39;00m\n\u001b[1;32m   3098\u001b[0m \u001b[38;5;124;03m            https://huggingface.co/docs/huggingface_hub/quick-start#authentication).\u001b[39;00m\n\u001b[1;32m   3099\u001b[0m \u001b[38;5;124;03m            To disable authentication, pass `False`.\u001b[39;00m\n\u001b[1;32m   3100\u001b[0m \n\u001b[1;32m   3101\u001b[0m \u001b[38;5;124;03m    Returns:\u001b[39;00m\n\u001b[1;32m   3102\u001b[0m \u001b[38;5;124;03m        `Iterable[Union[RepoFile, RepoFolder]]`:\u001b[39;00m\n\u001b[1;32m   3103\u001b[0m \u001b[38;5;124;03m            The information about the tree's files and folders, as an iterable of [`RepoFile`] and [`RepoFolder`] objects. The order of the files and folders is\u001b[39;00m\n\u001b[1;32m   3104\u001b[0m \u001b[38;5;124;03m            not guaranteed.\u001b[39;00m\n\u001b[1;32m   3105\u001b[0m \n\u001b[1;32m   3106\u001b[0m \u001b[38;5;124;03m    Raises:\u001b[39;00m\n\u001b[1;32m   3107\u001b[0m \u001b[38;5;124;03m        [`~utils.RepositoryNotFoundError`]:\u001b[39;00m\n\u001b[1;32m   3108\u001b[0m \u001b[38;5;124;03m            If repository is not found (error 404): wrong repo_id/repo_type, private but not authenticated or repo\u001b[39;00m\n\u001b[1;32m   3109\u001b[0m \u001b[38;5;124;03m            does not exist.\u001b[39;00m\n\u001b[1;32m   3110\u001b[0m \u001b[38;5;124;03m        [`~utils.RevisionNotFoundError`]:\u001b[39;00m\n\u001b[1;32m   3111\u001b[0m \u001b[38;5;124;03m            If revision is not found (error 404) on the repo.\u001b[39;00m\n\u001b[1;32m   3112\u001b[0m \u001b[38;5;124;03m        [`~utils.EntryNotFoundError`]:\u001b[39;00m\n\u001b[1;32m   3113\u001b[0m \u001b[38;5;124;03m            If the tree (folder) does not exist (error 404) on the repo.\u001b[39;00m\n\u001b[1;32m   3114\u001b[0m \n\u001b[1;32m   3115\u001b[0m \u001b[38;5;124;03m    Examples:\u001b[39;00m\n\u001b[1;32m   3116\u001b[0m \n\u001b[1;32m   3117\u001b[0m \u001b[38;5;124;03m        Get information about a repo's tree.\u001b[39;00m\n\u001b[1;32m   3118\u001b[0m \u001b[38;5;124;03m        ```py\u001b[39;00m\n\u001b[1;32m   3119\u001b[0m \u001b[38;5;124;03m        >>> from huggingface_hub import list_repo_tree\u001b[39;00m\n\u001b[1;32m   3120\u001b[0m \u001b[38;5;124;03m        >>> repo_tree = list_repo_tree(\"lysandre/arxiv-nlp\")\u001b[39;00m\n\u001b[1;32m   3121\u001b[0m \u001b[38;5;124;03m        >>> repo_tree\u001b[39;00m\n\u001b[1;32m   3122\u001b[0m \u001b[38;5;124;03m        <generator object HfApi.list_repo_tree at 0x7fa4088e1ac0>\u001b[39;00m\n\u001b[1;32m   3123\u001b[0m \u001b[38;5;124;03m        >>> list(repo_tree)\u001b[39;00m\n\u001b[1;32m   3124\u001b[0m \u001b[38;5;124;03m        [\u001b[39;00m\n\u001b[1;32m   3125\u001b[0m \u001b[38;5;124;03m            RepoFile(path='.gitattributes', size=391, blob_id='ae8c63daedbd4206d7d40126955d4e6ab1c80f8f', lfs=None, last_commit=None, security=None),\u001b[39;00m\n\u001b[1;32m   3126\u001b[0m \u001b[38;5;124;03m            RepoFile(path='README.md', size=391, blob_id='43bd404b159de6fba7c2f4d3264347668d43af25', lfs=None, last_commit=None, security=None),\u001b[39;00m\n\u001b[1;32m   3127\u001b[0m \u001b[38;5;124;03m            RepoFile(path='config.json', size=554, blob_id='2f9618c3a19b9a61add74f70bfb121335aeef666', lfs=None, last_commit=None, security=None),\u001b[39;00m\n\u001b[1;32m   3128\u001b[0m \u001b[38;5;124;03m            RepoFile(\u001b[39;00m\n\u001b[1;32m   3129\u001b[0m \u001b[38;5;124;03m                path='flax_model.msgpack', size=497764107, blob_id='8095a62ccb4d806da7666fcda07467e2d150218e',\u001b[39;00m\n\u001b[1;32m   3130\u001b[0m \u001b[38;5;124;03m                lfs={'size': 497764107, 'sha256': 'd88b0d6a6ff9c3f8151f9d3228f57092aaea997f09af009eefd7373a77b5abb9', 'pointer_size': 134}, last_commit=None, security=None\u001b[39;00m\n\u001b[1;32m   3131\u001b[0m \u001b[38;5;124;03m            ),\u001b[39;00m\n\u001b[1;32m   3132\u001b[0m \u001b[38;5;124;03m            RepoFile(path='merges.txt', size=456318, blob_id='226b0752cac7789c48f0cb3ec53eda48b7be36cc', lfs=None, last_commit=None, security=None),\u001b[39;00m\n\u001b[1;32m   3133\u001b[0m \u001b[38;5;124;03m            RepoFile(\u001b[39;00m\n\u001b[1;32m   3134\u001b[0m \u001b[38;5;124;03m                path='pytorch_model.bin', size=548123560, blob_id='64eaa9c526867e404b68f2c5d66fd78e27026523',\u001b[39;00m\n\u001b[1;32m   3135\u001b[0m \u001b[38;5;124;03m                lfs={'size': 548123560, 'sha256': '9be78edb5b928eba33aa88f431551348f7466ba9f5ef3daf1d552398722a5436', 'pointer_size': 134}, last_commit=None, security=None\u001b[39;00m\n\u001b[1;32m   3136\u001b[0m \u001b[38;5;124;03m            ),\u001b[39;00m\n\u001b[1;32m   3137\u001b[0m \u001b[38;5;124;03m            RepoFile(path='vocab.json', size=898669, blob_id='b00361fece0387ca34b4b8b8539ed830d644dbeb', lfs=None, last_commit=None, security=None)]\u001b[39;00m\n\u001b[1;32m   3138\u001b[0m \u001b[38;5;124;03m        ]\u001b[39;00m\n\u001b[1;32m   3139\u001b[0m \u001b[38;5;124;03m        ```\u001b[39;00m\n\u001b[1;32m   3140\u001b[0m \n\u001b[1;32m   3141\u001b[0m \u001b[38;5;124;03m        Get even more information about a repo's tree (last commit and files' security scan results)\u001b[39;00m\n\u001b[1;32m   3142\u001b[0m \u001b[38;5;124;03m        ```py\u001b[39;00m\n\u001b[1;32m   3143\u001b[0m \u001b[38;5;124;03m        >>> from huggingface_hub import list_repo_tree\u001b[39;00m\n\u001b[1;32m   3144\u001b[0m \u001b[38;5;124;03m        >>> repo_tree = list_repo_tree(\"prompthero/openjourney-v4\", expand=True)\u001b[39;00m\n\u001b[1;32m   3145\u001b[0m \u001b[38;5;124;03m        >>> list(repo_tree)\u001b[39;00m\n\u001b[1;32m   3146\u001b[0m \u001b[38;5;124;03m        [\u001b[39;00m\n\u001b[1;32m   3147\u001b[0m \u001b[38;5;124;03m            RepoFolder(\u001b[39;00m\n\u001b[1;32m   3148\u001b[0m \u001b[38;5;124;03m                path='feature_extractor',\u001b[39;00m\n\u001b[1;32m   3149\u001b[0m \u001b[38;5;124;03m                tree_id='aa536c4ea18073388b5b0bc791057a7296a00398',\u001b[39;00m\n\u001b[1;32m   3150\u001b[0m \u001b[38;5;124;03m                last_commit={\u001b[39;00m\n\u001b[1;32m   3151\u001b[0m \u001b[38;5;124;03m                    'oid': '47b62b20b20e06b9de610e840282b7e6c3d51190',\u001b[39;00m\n\u001b[1;32m   3152\u001b[0m \u001b[38;5;124;03m                    'title': 'Upload diffusers weights (#48)',\u001b[39;00m\n\u001b[1;32m   3153\u001b[0m \u001b[38;5;124;03m                    'date': datetime.datetime(2023, 3, 21, 9, 5, 27, tzinfo=datetime.timezone.utc)\u001b[39;00m\n\u001b[1;32m   3154\u001b[0m \u001b[38;5;124;03m                }\u001b[39;00m\n\u001b[1;32m   3155\u001b[0m \u001b[38;5;124;03m            ),\u001b[39;00m\n\u001b[1;32m   3156\u001b[0m \u001b[38;5;124;03m            RepoFolder(\u001b[39;00m\n\u001b[1;32m   3157\u001b[0m \u001b[38;5;124;03m                path='safety_checker',\u001b[39;00m\n\u001b[1;32m   3158\u001b[0m \u001b[38;5;124;03m                tree_id='65aef9d787e5557373fdf714d6c34d4fcdd70440',\u001b[39;00m\n\u001b[1;32m   3159\u001b[0m \u001b[38;5;124;03m                last_commit={\u001b[39;00m\n\u001b[1;32m   3160\u001b[0m \u001b[38;5;124;03m                    'oid': '47b62b20b20e06b9de610e840282b7e6c3d51190',\u001b[39;00m\n\u001b[1;32m   3161\u001b[0m \u001b[38;5;124;03m                    'title': 'Upload diffusers weights (#48)',\u001b[39;00m\n\u001b[1;32m   3162\u001b[0m \u001b[38;5;124;03m                    'date': datetime.datetime(2023, 3, 21, 9, 5, 27, tzinfo=datetime.timezone.utc)\u001b[39;00m\n\u001b[1;32m   3163\u001b[0m \u001b[38;5;124;03m                }\u001b[39;00m\n\u001b[1;32m   3164\u001b[0m \u001b[38;5;124;03m            ),\u001b[39;00m\n\u001b[1;32m   3165\u001b[0m \u001b[38;5;124;03m            RepoFile(\u001b[39;00m\n\u001b[1;32m   3166\u001b[0m \u001b[38;5;124;03m                path='model_index.json',\u001b[39;00m\n\u001b[1;32m   3167\u001b[0m \u001b[38;5;124;03m                size=582,\u001b[39;00m\n\u001b[1;32m   3168\u001b[0m \u001b[38;5;124;03m                blob_id='d3d7c1e8c3e78eeb1640b8e2041ee256e24c9ee1',\u001b[39;00m\n\u001b[1;32m   3169\u001b[0m \u001b[38;5;124;03m                lfs=None,\u001b[39;00m\n\u001b[1;32m   3170\u001b[0m \u001b[38;5;124;03m                last_commit={\u001b[39;00m\n\u001b[1;32m   3171\u001b[0m \u001b[38;5;124;03m                    'oid': 'b195ed2d503f3eb29637050a886d77bd81d35f0e',\u001b[39;00m\n\u001b[1;32m   3172\u001b[0m \u001b[38;5;124;03m                    'title': 'Fix deprecation warning by changing `CLIPFeatureExtractor` to `CLIPImageProcessor`. (#54)',\u001b[39;00m\n\u001b[1;32m   3173\u001b[0m \u001b[38;5;124;03m                    'date': datetime.datetime(2023, 5, 15, 21, 41, 59, tzinfo=datetime.timezone.utc)\u001b[39;00m\n\u001b[1;32m   3174\u001b[0m \u001b[38;5;124;03m                },\u001b[39;00m\n\u001b[1;32m   3175\u001b[0m \u001b[38;5;124;03m                security={\u001b[39;00m\n\u001b[1;32m   3176\u001b[0m \u001b[38;5;124;03m                    'safe': True,\u001b[39;00m\n\u001b[1;32m   3177\u001b[0m \u001b[38;5;124;03m                    'av_scan': {'virusFound': False, 'virusNames': None},\u001b[39;00m\n\u001b[1;32m   3178\u001b[0m \u001b[38;5;124;03m                    'pickle_import_scan': None\u001b[39;00m\n\u001b[1;32m   3179\u001b[0m \u001b[38;5;124;03m                }\u001b[39;00m\n\u001b[1;32m   3180\u001b[0m \u001b[38;5;124;03m            )\u001b[39;00m\n\u001b[1;32m   3181\u001b[0m \u001b[38;5;124;03m            ...\u001b[39;00m\n\u001b[1;32m   3182\u001b[0m \u001b[38;5;124;03m        ]\u001b[39;00m\n\u001b[1;32m   3183\u001b[0m \u001b[38;5;124;03m        ```\u001b[39;00m\n\u001b[1;32m   3184\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   3185\u001b[0m     repo_type \u001b[38;5;241m=\u001b[39m repo_type \u001b[38;5;129;01mor\u001b[39;00m constants\u001b[38;5;241m.\u001b[39mREPO_TYPE_MODEL\n",
      "File \u001b[0;32m~/miniconda3/envs/project/lib/python3.10/site-packages/huggingface_hub/utils/_pagination.py:37\u001b[0m, in \u001b[0;36mpaginate\u001b[0;34m(path, params, headers)\u001b[0m\n\u001b[1;32m     36\u001b[0m r \u001b[38;5;241m=\u001b[39m session\u001b[38;5;241m.\u001b[39mget(path, params\u001b[38;5;241m=\u001b[39mparams, headers\u001b[38;5;241m=\u001b[39mheaders)\n\u001b[0;32m---> 37\u001b[0m \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m r\u001b[38;5;241m.\u001b[39mjson()\n",
      "File \u001b[0;32m~/miniconda3/envs/project/lib/python3.10/site-packages/huggingface_hub/utils/_http.py:567\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m k\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauthorization\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 567\u001b[0m     v \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<TOKEN>\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Hide authorization header, no matter its value (can be Bearer, Key, etc.)\u001b[39;00m\n\u001b[1;32m    568\u001b[0m parts \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-H\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(k, v))]\n",
      "\u001b[0;31mRemoteEntryNotFoundError\u001b[0m: 404 Client Error. (Request ID: Root=1-691b89b0-228160741791331e251b85bc;2ba16ceb-0e94-4d29-983b-6acced2d6a6f)\n\nEntry Not Found for url: https://huggingface.co/api/models/Qwen/Qwen2-VL-2B-Instruct/tree/main/additional_chat_templates?recursive=false&expand=false.\nadditional_chat_templates does not exist on \"main\"",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mHTTPStatusError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/project/lib/python3.10/site-packages/huggingface_hub/utils/_http.py:553\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    552\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_curlify\u001b[39m(request: requests\u001b[38;5;241m.\u001b[39mPreparedRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m--> 553\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Convert a `requests.PreparedRequest` into a curl command (str).\u001b[39;00m\n\u001b[1;32m    554\u001b[0m \n\u001b[1;32m    555\u001b[0m \u001b[38;5;124;03m    Used for debug purposes only.\u001b[39;00m\n\u001b[1;32m    556\u001b[0m \n\u001b[1;32m    557\u001b[0m \u001b[38;5;124;03m    Implementation vendored from https://github.com/ofw/curlify/blob/master/curlify.py.\u001b[39;00m\n\u001b[1;32m    558\u001b[0m \u001b[38;5;124;03m    MIT License Copyright (c) 2016 Egor.\u001b[39;00m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    560\u001b[0m     parts: List[Tuple[Any, Any]] \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    561\u001b[0m         (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcurl\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    562\u001b[0m         (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-X\u001b[39m\u001b[38;5;124m\"\u001b[39m, request\u001b[38;5;241m.\u001b[39mmethod),\n\u001b[1;32m    563\u001b[0m     ]\n",
      "File \u001b[0;32m~/miniconda3/envs/project/lib/python3.10/site-packages/httpx/_models.py:829\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    828\u001b[0m message \u001b[38;5;241m=\u001b[39m message\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m, error_type\u001b[38;5;241m=\u001b[39merror_type)\n\u001b[0;32m--> 829\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m HTTPStatusError(message, request\u001b[38;5;241m=\u001b[39mrequest, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPStatusError\u001b[0m: Client error '404 Not Found' for url 'https://huggingface.co/api/models/Qwen/Qwen2-VL-2B-Instruct/tree/main/additional_chat_templates?recursive=false&expand=false'\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRemoteEntryNotFoundError\u001b[0m                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;66;03m# Set environment variable to skip optional files\u001b[39;00m\n\u001b[1;32m     25\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHF_HUB_DISABLE_EXPERIMENTAL_WARNING\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 26\u001b[0m     processor \u001b[38;5;241m=\u001b[39m \u001b[43mAutoProcessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m        \u001b[49m\u001b[43mMODEL_ID\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✓ Processor loaded (ignoring missing optional files)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e2:\n",
      "File \u001b[0;32m~/miniconda3/envs/project/lib/python3.10/site-packages/transformers/models/auto/processing_auto.py:396\u001b[0m, in \u001b[0;36mAutoProcessor.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m processor_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m    393\u001b[0m         pretrained_model_name_or_path, trust_remote_code\u001b[38;5;241m=\u001b[39mtrust_remote_code, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    394\u001b[0m     )\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m processor_class \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 396\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprocessor_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;66;03m# Last try: we use the PROCESSOR_MAPPING.\u001b[39;00m\n\u001b[1;32m    400\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m PROCESSOR_MAPPING:\n",
      "File \u001b[0;32m~/miniconda3/envs/project/lib/python3.10/site-packages/transformers/processing_utils.py:1394\u001b[0m, in \u001b[0;36mProcessorMixin.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, **kwargs)\u001b[0m\n\u001b[1;32m   1391\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1392\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m token\n\u001b[0;32m-> 1394\u001b[0m args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_arguments_from_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1395\u001b[0m processor_dict, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mget_processor_dict(pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1396\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_args_and_dict(args, processor_dict, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/project/lib/python3.10/site-packages/transformers/processing_utils.py:1453\u001b[0m, in \u001b[0;36mProcessorMixin._get_arguments_from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m   1450\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1451\u001b[0m         attribute_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mget_possibly_dynamic_module(class_name)\n\u001b[0;32m-> 1453\u001b[0m     args\u001b[38;5;241m.\u001b[39mappend(\u001b[43mattribute_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1455\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m args\n",
      "File \u001b[0;32m~/miniconda3/envs/project/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2038\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   2034\u001b[0m             vocab_files[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchat_template_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtemplate_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2035\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mCHAT_TEMPLATE_DIR\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtemplate_file\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2036\u001b[0m             )\n\u001b[1;32m   2037\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2038\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m template \u001b[38;5;129;01min\u001b[39;00m \u001b[43mlist_repo_templates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2039\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2040\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2041\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2042\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2043\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2044\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   2045\u001b[0m         template \u001b[38;5;241m=\u001b[39m template\u001b[38;5;241m.\u001b[39mremovesuffix(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.jinja\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2046\u001b[0m         vocab_files[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchat_template_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtemplate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mCHAT_TEMPLATE_DIR\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtemplate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.jinja\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/project/lib/python3.10/site-packages/transformers/utils/hub.py:167\u001b[0m, in \u001b[0;36mlist_repo_templates\u001b[0;34m(repo_id, local_files_only, revision, cache_dir, token)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m local_files_only:\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 167\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m    168\u001b[0m             entry\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mremoveprefix(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mCHAT_TEMPLATE_DIR\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    169\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m entry \u001b[38;5;129;01min\u001b[39;00m list_repo_tree(\n\u001b[1;32m    170\u001b[0m                 repo_id\u001b[38;5;241m=\u001b[39mrepo_id,\n\u001b[1;32m    171\u001b[0m                 revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[1;32m    172\u001b[0m                 path_in_repo\u001b[38;5;241m=\u001b[39mCHAT_TEMPLATE_DIR,\n\u001b[1;32m    173\u001b[0m                 recursive\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    174\u001b[0m                 token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[1;32m    175\u001b[0m             )\n\u001b[1;32m    176\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m entry\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.jinja\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    177\u001b[0m         ]\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (GatedRepoError, RepositoryNotFoundError, RevisionNotFoundError):\n\u001b[1;32m    179\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m  \u001b[38;5;66;03m# valid errors => do not catch\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/project/lib/python3.10/site-packages/transformers/utils/hub.py:167\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m local_files_only:\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 167\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m    168\u001b[0m             entry\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mremoveprefix(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mCHAT_TEMPLATE_DIR\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    169\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m entry \u001b[38;5;129;01min\u001b[39;00m list_repo_tree(\n\u001b[1;32m    170\u001b[0m                 repo_id\u001b[38;5;241m=\u001b[39mrepo_id,\n\u001b[1;32m    171\u001b[0m                 revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[1;32m    172\u001b[0m                 path_in_repo\u001b[38;5;241m=\u001b[39mCHAT_TEMPLATE_DIR,\n\u001b[1;32m    173\u001b[0m                 recursive\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    174\u001b[0m                 token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[1;32m    175\u001b[0m             )\n\u001b[1;32m    176\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m entry\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.jinja\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    177\u001b[0m         ]\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (GatedRepoError, RepositoryNotFoundError, RevisionNotFoundError):\n\u001b[1;32m    179\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m  \u001b[38;5;66;03m# valid errors => do not catch\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/project/lib/python3.10/site-packages/huggingface_hub/hf_api.py:3082\u001b[0m, in \u001b[0;36mlist_repo_tree\u001b[0;34m(self, repo_id, path_in_repo, recursive, expand, revision, repo_type, token)\u001b[0m\n\u001b[1;32m   3062\u001b[0m \u001b[38;5;129m@validate_hf_hub_args\u001b[39m\n\u001b[1;32m   3063\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mlist_repo_tree\u001b[39m(\n\u001b[1;32m   3064\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3072\u001b[0m     token: Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   3073\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterable[Union[RepoFile, RepoFolder]]:\n\u001b[1;32m   3074\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3075\u001b[0m \u001b[38;5;124;03m    List a repo tree's files and folders and get information about them.\u001b[39;00m\n\u001b[1;32m   3076\u001b[0m \n\u001b[1;32m   3077\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   3078\u001b[0m \u001b[38;5;124;03m        repo_id (`str`):\u001b[39;00m\n\u001b[1;32m   3079\u001b[0m \u001b[38;5;124;03m            A namespace (user or an organization) and a repo name separated by a `/`.\u001b[39;00m\n\u001b[1;32m   3080\u001b[0m \u001b[38;5;124;03m        path_in_repo (`str`, *optional*):\u001b[39;00m\n\u001b[1;32m   3081\u001b[0m \u001b[38;5;124;03m            Relative path of the tree (folder) in the repo, for example:\u001b[39;00m\n\u001b[0;32m-> 3082\u001b[0m \u001b[38;5;124;03m            `\"checkpoints/1fec34a/results\"`. Will default to the root tree (folder) of the repository.\u001b[39;00m\n\u001b[1;32m   3083\u001b[0m \u001b[38;5;124;03m        recursive (`bool`, *optional*, defaults to `False`):\u001b[39;00m\n\u001b[1;32m   3084\u001b[0m \u001b[38;5;124;03m            Whether to list tree's files and folders recursively.\u001b[39;00m\n\u001b[1;32m   3085\u001b[0m \u001b[38;5;124;03m        expand (`bool`, *optional*, defaults to `False`):\u001b[39;00m\n\u001b[1;32m   3086\u001b[0m \u001b[38;5;124;03m            Whether to fetch more information about the tree's files and folders (e.g. last commit and files' security scan results). This\u001b[39;00m\n\u001b[1;32m   3087\u001b[0m \u001b[38;5;124;03m            operation is more expensive for the server so only 50 results are returned per page (instead of 1000).\u001b[39;00m\n\u001b[1;32m   3088\u001b[0m \u001b[38;5;124;03m            As pagination is implemented in `huggingface_hub`, this is transparent for you except for the time it\u001b[39;00m\n\u001b[1;32m   3089\u001b[0m \u001b[38;5;124;03m            takes to get the results.\u001b[39;00m\n\u001b[1;32m   3090\u001b[0m \u001b[38;5;124;03m        revision (`str`, *optional*):\u001b[39;00m\n\u001b[1;32m   3091\u001b[0m \u001b[38;5;124;03m            The revision of the repository from which to get the tree. Defaults to `\"main\"` branch.\u001b[39;00m\n\u001b[1;32m   3092\u001b[0m \u001b[38;5;124;03m        repo_type (`str`, *optional*):\u001b[39;00m\n\u001b[1;32m   3093\u001b[0m \u001b[38;5;124;03m            The type of the repository from which to get the tree (`\"model\"`, `\"dataset\"` or `\"space\"`.\u001b[39;00m\n\u001b[1;32m   3094\u001b[0m \u001b[38;5;124;03m            Defaults to `\"model\"`.\u001b[39;00m\n\u001b[1;32m   3095\u001b[0m \u001b[38;5;124;03m        token (`bool` or `str`, *optional*):\u001b[39;00m\n\u001b[1;32m   3096\u001b[0m \u001b[38;5;124;03m            A valid user access token (string). Defaults to the locally saved\u001b[39;00m\n\u001b[1;32m   3097\u001b[0m \u001b[38;5;124;03m            token, which is the recommended method for authentication (see\u001b[39;00m\n\u001b[1;32m   3098\u001b[0m \u001b[38;5;124;03m            https://huggingface.co/docs/huggingface_hub/quick-start#authentication).\u001b[39;00m\n\u001b[1;32m   3099\u001b[0m \u001b[38;5;124;03m            To disable authentication, pass `False`.\u001b[39;00m\n\u001b[1;32m   3100\u001b[0m \n\u001b[1;32m   3101\u001b[0m \u001b[38;5;124;03m    Returns:\u001b[39;00m\n\u001b[1;32m   3102\u001b[0m \u001b[38;5;124;03m        `Iterable[Union[RepoFile, RepoFolder]]`:\u001b[39;00m\n\u001b[1;32m   3103\u001b[0m \u001b[38;5;124;03m            The information about the tree's files and folders, as an iterable of [`RepoFile`] and [`RepoFolder`] objects. The order of the files and folders is\u001b[39;00m\n\u001b[1;32m   3104\u001b[0m \u001b[38;5;124;03m            not guaranteed.\u001b[39;00m\n\u001b[1;32m   3105\u001b[0m \n\u001b[1;32m   3106\u001b[0m \u001b[38;5;124;03m    Raises:\u001b[39;00m\n\u001b[1;32m   3107\u001b[0m \u001b[38;5;124;03m        [`~utils.RepositoryNotFoundError`]:\u001b[39;00m\n\u001b[1;32m   3108\u001b[0m \u001b[38;5;124;03m            If repository is not found (error 404): wrong repo_id/repo_type, private but not authenticated or repo\u001b[39;00m\n\u001b[1;32m   3109\u001b[0m \u001b[38;5;124;03m            does not exist.\u001b[39;00m\n\u001b[1;32m   3110\u001b[0m \u001b[38;5;124;03m        [`~utils.RevisionNotFoundError`]:\u001b[39;00m\n\u001b[1;32m   3111\u001b[0m \u001b[38;5;124;03m            If revision is not found (error 404) on the repo.\u001b[39;00m\n\u001b[1;32m   3112\u001b[0m \u001b[38;5;124;03m        [`~utils.EntryNotFoundError`]:\u001b[39;00m\n\u001b[1;32m   3113\u001b[0m \u001b[38;5;124;03m            If the tree (folder) does not exist (error 404) on the repo.\u001b[39;00m\n\u001b[1;32m   3114\u001b[0m \n\u001b[1;32m   3115\u001b[0m \u001b[38;5;124;03m    Examples:\u001b[39;00m\n\u001b[1;32m   3116\u001b[0m \n\u001b[1;32m   3117\u001b[0m \u001b[38;5;124;03m        Get information about a repo's tree.\u001b[39;00m\n\u001b[1;32m   3118\u001b[0m \u001b[38;5;124;03m        ```py\u001b[39;00m\n\u001b[1;32m   3119\u001b[0m \u001b[38;5;124;03m        >>> from huggingface_hub import list_repo_tree\u001b[39;00m\n\u001b[1;32m   3120\u001b[0m \u001b[38;5;124;03m        >>> repo_tree = list_repo_tree(\"lysandre/arxiv-nlp\")\u001b[39;00m\n\u001b[1;32m   3121\u001b[0m \u001b[38;5;124;03m        >>> repo_tree\u001b[39;00m\n\u001b[1;32m   3122\u001b[0m \u001b[38;5;124;03m        <generator object HfApi.list_repo_tree at 0x7fa4088e1ac0>\u001b[39;00m\n\u001b[1;32m   3123\u001b[0m \u001b[38;5;124;03m        >>> list(repo_tree)\u001b[39;00m\n\u001b[1;32m   3124\u001b[0m \u001b[38;5;124;03m        [\u001b[39;00m\n\u001b[1;32m   3125\u001b[0m \u001b[38;5;124;03m            RepoFile(path='.gitattributes', size=391, blob_id='ae8c63daedbd4206d7d40126955d4e6ab1c80f8f', lfs=None, last_commit=None, security=None),\u001b[39;00m\n\u001b[1;32m   3126\u001b[0m \u001b[38;5;124;03m            RepoFile(path='README.md', size=391, blob_id='43bd404b159de6fba7c2f4d3264347668d43af25', lfs=None, last_commit=None, security=None),\u001b[39;00m\n\u001b[1;32m   3127\u001b[0m \u001b[38;5;124;03m            RepoFile(path='config.json', size=554, blob_id='2f9618c3a19b9a61add74f70bfb121335aeef666', lfs=None, last_commit=None, security=None),\u001b[39;00m\n\u001b[1;32m   3128\u001b[0m \u001b[38;5;124;03m            RepoFile(\u001b[39;00m\n\u001b[1;32m   3129\u001b[0m \u001b[38;5;124;03m                path='flax_model.msgpack', size=497764107, blob_id='8095a62ccb4d806da7666fcda07467e2d150218e',\u001b[39;00m\n\u001b[1;32m   3130\u001b[0m \u001b[38;5;124;03m                lfs={'size': 497764107, 'sha256': 'd88b0d6a6ff9c3f8151f9d3228f57092aaea997f09af009eefd7373a77b5abb9', 'pointer_size': 134}, last_commit=None, security=None\u001b[39;00m\n\u001b[1;32m   3131\u001b[0m \u001b[38;5;124;03m            ),\u001b[39;00m\n\u001b[1;32m   3132\u001b[0m \u001b[38;5;124;03m            RepoFile(path='merges.txt', size=456318, blob_id='226b0752cac7789c48f0cb3ec53eda48b7be36cc', lfs=None, last_commit=None, security=None),\u001b[39;00m\n\u001b[1;32m   3133\u001b[0m \u001b[38;5;124;03m            RepoFile(\u001b[39;00m\n\u001b[1;32m   3134\u001b[0m \u001b[38;5;124;03m                path='pytorch_model.bin', size=548123560, blob_id='64eaa9c526867e404b68f2c5d66fd78e27026523',\u001b[39;00m\n\u001b[1;32m   3135\u001b[0m \u001b[38;5;124;03m                lfs={'size': 548123560, 'sha256': '9be78edb5b928eba33aa88f431551348f7466ba9f5ef3daf1d552398722a5436', 'pointer_size': 134}, last_commit=None, security=None\u001b[39;00m\n\u001b[1;32m   3136\u001b[0m \u001b[38;5;124;03m            ),\u001b[39;00m\n\u001b[1;32m   3137\u001b[0m \u001b[38;5;124;03m            RepoFile(path='vocab.json', size=898669, blob_id='b00361fece0387ca34b4b8b8539ed830d644dbeb', lfs=None, last_commit=None, security=None)]\u001b[39;00m\n\u001b[1;32m   3138\u001b[0m \u001b[38;5;124;03m        ]\u001b[39;00m\n\u001b[1;32m   3139\u001b[0m \u001b[38;5;124;03m        ```\u001b[39;00m\n\u001b[1;32m   3140\u001b[0m \n\u001b[1;32m   3141\u001b[0m \u001b[38;5;124;03m        Get even more information about a repo's tree (last commit and files' security scan results)\u001b[39;00m\n\u001b[1;32m   3142\u001b[0m \u001b[38;5;124;03m        ```py\u001b[39;00m\n\u001b[1;32m   3143\u001b[0m \u001b[38;5;124;03m        >>> from huggingface_hub import list_repo_tree\u001b[39;00m\n\u001b[1;32m   3144\u001b[0m \u001b[38;5;124;03m        >>> repo_tree = list_repo_tree(\"prompthero/openjourney-v4\", expand=True)\u001b[39;00m\n\u001b[1;32m   3145\u001b[0m \u001b[38;5;124;03m        >>> list(repo_tree)\u001b[39;00m\n\u001b[1;32m   3146\u001b[0m \u001b[38;5;124;03m        [\u001b[39;00m\n\u001b[1;32m   3147\u001b[0m \u001b[38;5;124;03m            RepoFolder(\u001b[39;00m\n\u001b[1;32m   3148\u001b[0m \u001b[38;5;124;03m                path='feature_extractor',\u001b[39;00m\n\u001b[1;32m   3149\u001b[0m \u001b[38;5;124;03m                tree_id='aa536c4ea18073388b5b0bc791057a7296a00398',\u001b[39;00m\n\u001b[1;32m   3150\u001b[0m \u001b[38;5;124;03m                last_commit={\u001b[39;00m\n\u001b[1;32m   3151\u001b[0m \u001b[38;5;124;03m                    'oid': '47b62b20b20e06b9de610e840282b7e6c3d51190',\u001b[39;00m\n\u001b[1;32m   3152\u001b[0m \u001b[38;5;124;03m                    'title': 'Upload diffusers weights (#48)',\u001b[39;00m\n\u001b[1;32m   3153\u001b[0m \u001b[38;5;124;03m                    'date': datetime.datetime(2023, 3, 21, 9, 5, 27, tzinfo=datetime.timezone.utc)\u001b[39;00m\n\u001b[1;32m   3154\u001b[0m \u001b[38;5;124;03m                }\u001b[39;00m\n\u001b[1;32m   3155\u001b[0m \u001b[38;5;124;03m            ),\u001b[39;00m\n\u001b[1;32m   3156\u001b[0m \u001b[38;5;124;03m            RepoFolder(\u001b[39;00m\n\u001b[1;32m   3157\u001b[0m \u001b[38;5;124;03m                path='safety_checker',\u001b[39;00m\n\u001b[1;32m   3158\u001b[0m \u001b[38;5;124;03m                tree_id='65aef9d787e5557373fdf714d6c34d4fcdd70440',\u001b[39;00m\n\u001b[1;32m   3159\u001b[0m \u001b[38;5;124;03m                last_commit={\u001b[39;00m\n\u001b[1;32m   3160\u001b[0m \u001b[38;5;124;03m                    'oid': '47b62b20b20e06b9de610e840282b7e6c3d51190',\u001b[39;00m\n\u001b[1;32m   3161\u001b[0m \u001b[38;5;124;03m                    'title': 'Upload diffusers weights (#48)',\u001b[39;00m\n\u001b[1;32m   3162\u001b[0m \u001b[38;5;124;03m                    'date': datetime.datetime(2023, 3, 21, 9, 5, 27, tzinfo=datetime.timezone.utc)\u001b[39;00m\n\u001b[1;32m   3163\u001b[0m \u001b[38;5;124;03m                }\u001b[39;00m\n\u001b[1;32m   3164\u001b[0m \u001b[38;5;124;03m            ),\u001b[39;00m\n\u001b[1;32m   3165\u001b[0m \u001b[38;5;124;03m            RepoFile(\u001b[39;00m\n\u001b[1;32m   3166\u001b[0m \u001b[38;5;124;03m                path='model_index.json',\u001b[39;00m\n\u001b[1;32m   3167\u001b[0m \u001b[38;5;124;03m                size=582,\u001b[39;00m\n\u001b[1;32m   3168\u001b[0m \u001b[38;5;124;03m                blob_id='d3d7c1e8c3e78eeb1640b8e2041ee256e24c9ee1',\u001b[39;00m\n\u001b[1;32m   3169\u001b[0m \u001b[38;5;124;03m                lfs=None,\u001b[39;00m\n\u001b[1;32m   3170\u001b[0m \u001b[38;5;124;03m                last_commit={\u001b[39;00m\n\u001b[1;32m   3171\u001b[0m \u001b[38;5;124;03m                    'oid': 'b195ed2d503f3eb29637050a886d77bd81d35f0e',\u001b[39;00m\n\u001b[1;32m   3172\u001b[0m \u001b[38;5;124;03m                    'title': 'Fix deprecation warning by changing `CLIPFeatureExtractor` to `CLIPImageProcessor`. (#54)',\u001b[39;00m\n\u001b[1;32m   3173\u001b[0m \u001b[38;5;124;03m                    'date': datetime.datetime(2023, 5, 15, 21, 41, 59, tzinfo=datetime.timezone.utc)\u001b[39;00m\n\u001b[1;32m   3174\u001b[0m \u001b[38;5;124;03m                },\u001b[39;00m\n\u001b[1;32m   3175\u001b[0m \u001b[38;5;124;03m                security={\u001b[39;00m\n\u001b[1;32m   3176\u001b[0m \u001b[38;5;124;03m                    'safe': True,\u001b[39;00m\n\u001b[1;32m   3177\u001b[0m \u001b[38;5;124;03m                    'av_scan': {'virusFound': False, 'virusNames': None},\u001b[39;00m\n\u001b[1;32m   3178\u001b[0m \u001b[38;5;124;03m                    'pickle_import_scan': None\u001b[39;00m\n\u001b[1;32m   3179\u001b[0m \u001b[38;5;124;03m                }\u001b[39;00m\n\u001b[1;32m   3180\u001b[0m \u001b[38;5;124;03m            )\u001b[39;00m\n\u001b[1;32m   3181\u001b[0m \u001b[38;5;124;03m            ...\u001b[39;00m\n\u001b[1;32m   3182\u001b[0m \u001b[38;5;124;03m        ]\u001b[39;00m\n\u001b[1;32m   3183\u001b[0m \u001b[38;5;124;03m        ```\u001b[39;00m\n\u001b[1;32m   3184\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   3185\u001b[0m     repo_type \u001b[38;5;241m=\u001b[39m repo_type \u001b[38;5;129;01mor\u001b[39;00m constants\u001b[38;5;241m.\u001b[39mREPO_TYPE_MODEL\n\u001b[1;32m   3186\u001b[0m     revision \u001b[38;5;241m=\u001b[39m quote(revision, safe\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m revision \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m constants\u001b[38;5;241m.\u001b[39mDEFAULT_REVISION\n",
      "File \u001b[0;32m~/miniconda3/envs/project/lib/python3.10/site-packages/huggingface_hub/utils/_pagination.py:37\u001b[0m, in \u001b[0;36mpaginate\u001b[0;34m(path, params, headers)\u001b[0m\n\u001b[1;32m     35\u001b[0m session \u001b[38;5;241m=\u001b[39m get_session()\n\u001b[1;32m     36\u001b[0m r \u001b[38;5;241m=\u001b[39m session\u001b[38;5;241m.\u001b[39mget(path, params\u001b[38;5;241m=\u001b[39mparams, headers\u001b[38;5;241m=\u001b[39mheaders)\n\u001b[0;32m---> 37\u001b[0m \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m r\u001b[38;5;241m.\u001b[39mjson()\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# Follow pages\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Next link already contains query params\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/project/lib/python3.10/site-packages/huggingface_hub/utils/_http.py:567\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(request\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mitems()):\n\u001b[1;32m    566\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m k\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauthorization\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 567\u001b[0m         v \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<TOKEN>\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Hide authorization header, no matter its value (can be Bearer, Key, etc.)\u001b[39;00m\n\u001b[1;32m    568\u001b[0m     parts \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-H\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(k, v))]\n\u001b[1;32m    570\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m request\u001b[38;5;241m.\u001b[39mbody:\n",
      "\u001b[0;31mRemoteEntryNotFoundError\u001b[0m: 404 Client Error. (Request ID: Root=1-691b89b2-6e0156535b770da2200d5812;4e982243-0128-425c-8e7c-2b7d756cdc8e)\n\nEntry Not Found for url: https://huggingface.co/api/models/Qwen/Qwen2-VL-2B-Instruct/tree/main/additional_chat_templates?recursive=false&expand=false.\nadditional_chat_templates does not exist on \"main\""
     ]
    }
   ],
   "source": [
    "from transformers import AutoProcessor, AutoModelForImageTextToText\n",
    "import torch\n",
    "import os\n",
    "from huggingface_hub.utils import HfHubHTTPError\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "MODEL_ID = \"Qwen/Qwen2-VL-2B-Instruct\"\n",
    "\n",
    "print(f\"Loading model: {MODEL_ID}\")\n",
    "print(f\"Device: {DEVICE}\")\n",
    "\n",
    "# Method 1: Try loading with error handling for missing optional files\n",
    "try:\n",
    "    processor = AutoProcessor.from_pretrained(\n",
    "        MODEL_ID,\n",
    "        trust_remote_code=True\n",
    "    )\n",
    "    print(\"✓ Processor loaded successfully\")\n",
    "except (HfHubHTTPError, Exception) as e:\n",
    "    if \"404\" in str(e) or \"additional_chat_templates\" in str(e):\n",
    "        print(f\"⚠️  Warning: Optional file missing ({e}), continuing anyway...\")\n",
    "        # Try loading without the optional file\n",
    "        try:\n",
    "            # Set environment variable to skip optional files\n",
    "            os.environ[\"HF_HUB_DISABLE_EXPERIMENTAL_WARNING\"] = \"1\"\n",
    "            processor = AutoProcessor.from_pretrained(\n",
    "                MODEL_ID,\n",
    "                trust_remote_code=True,\n",
    "                local_files_only=False\n",
    "            )\n",
    "            print(\"✓ Processor loaded (ignoring missing optional files)\")\n",
    "        except Exception as e2:\n",
    "            print(f\"✗ Could not load processor: {e2}\")\n",
    "            raise\n",
    "    else:\n",
    "        raise\n",
    "\n",
    "# Load model\n",
    "try:\n",
    "    model = AutoModelForImageTextToText.from_pretrained(\n",
    "        MODEL_ID,\n",
    "        device_map=\"auto\",\n",
    "        torch_dtype=torch.float16 if DEVICE==\"cuda\" else torch.float32,\n",
    "        trust_remote_code=True\n",
    "    ).eval()\n",
    "    print(\"✓ Model loaded successfully\")\n",
    "    print(f\"✓ Model on device: {next(model.parameters()).device}\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠️  Error with device_map='auto': {e}\")\n",
    "    print(\"Trying manual device placement...\")\n",
    "    model = AutoModelForImageTextToText.from_pretrained(\n",
    "        MODEL_ID,\n",
    "        torch_dtype=torch.float16 if DEVICE==\"cuda\" else torch.float32,\n",
    "        trust_remote_code=True\n",
    "    )\n",
    "    model = model.to(DEVICE).eval()\n",
    "    print(\"✓ Model loaded and moved to device\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_think_answer(q):\n",
    "    return f'''You are a medical VQA assistant. Think carefully but return ONLY valid JSON:\n",
    "{{\"answer\":\"<short answer>\"}}\n",
    "\n",
    "Rules:\n",
    "- Do not use code fences or backticks.\n",
    "- No extra keys or text beyond the JSON.\n",
    "- If your output is not valid JSON, immediately try again and output ONLY valid JSON.\n",
    "Question: \"{q}\"'''\n",
    "\n",
    "def prompt_caption_reason_answer(q):\n",
    "    return f'''You are a medical VQA assistant. First DESCRIBE the image, then REASON, then ANSWER.\n",
    "Return ONLY valid JSON with exactly these keys:\n",
    "{{\n",
    " \"caption\":\"<1-2 precise sentences about visible anatomy/findings>\",\n",
    " \"reasoning\":[\"<step1>\",\"<step2>\",\"<step3>\"],\n",
    " \"boxes\":[[x1,y1,x2,y2]],\n",
    " \"answer\":\"<short answer>\"\n",
    "}}\n",
    "Rules:\n",
    "- Do not use code fences or backticks.\n",
    "- No extra keys or text beyond the JSON.\n",
    "- Use integers for box coordinates within image bounds.\n",
    "- If your output is not valid JSON, immediately try again and output ONLY valid JSON.\n",
    "- Output at most 1 box tightly enclosing the most diagnostic finding (avoid full-organ boxes).\n",
    "- The box must be as small as possible while still covering the key evidence.\n",
    "\n",
    "Question: \"{q}\"'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory freed!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import gc\n",
    "\n",
    "# Delete variables\n",
    "if 'model' in globals():\n",
    "    del model\n",
    "if 'processor' in globals():\n",
    "    del processor\n",
    "\n",
    "# Clear cache\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "print(\"GPU memory freed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
